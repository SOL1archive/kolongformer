{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aad_1s7ybD5o"
      },
      "source": [
        "# `RoBERTa` --> `Longformer`: build a \"long\" version of pretrained models\n",
        "\n",
        "This notebook replicates the procedure descriped in the [Longformer paper](https://arxiv.org/abs/2004.05150) to train a Longformer model starting from the RoBERTa checkpoint. The same procedure can be applied to build the \"long\" version of other pretrained models as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3yjIYKXw3rL"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate -U --quiet\n",
        "!pip install datasets -U --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0NnMMl6wy7Q"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import math\n",
        "import copy\n",
        "import pathlib\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import RobertaTokenizerFast, DataCollatorForLanguageModeling, Trainer, AutoTokenizer\n",
        "from transformers import RobertaForMaskedLM, AutoModel, AutoModelForMaskedLM, LongformerForMaskedLM\n",
        "from transformers import TrainingArguments, HfArgumentParser\n",
        "from transformers import LongformerSelfAttention\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYn4WZ7rACVv",
        "outputId": "8ca6ee74-a9c1-4188-d421-ef22bc1237e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ],
      "metadata": {
        "id": "HLsUAkDYAESP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_path = '/content/drive/MyDrive/datasets/KorCrawl'\n",
        "main_path = Path(main_path)"
      ],
      "metadata": {
        "id": "k4vXHdqAAGLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgoNVJYUbD59"
      },
      "source": [
        "### RobertaLong\n",
        "\n",
        "`RobertaLongForMaskedLM` represents the \"long\" version of the `RoBERTa` model. It replaces `BertSelfAttention` with `RobertaLongSelfAttention`, which is a thin wrapper around `LongformerSelfAttention`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9EBISkRxPjO"
      },
      "outputs": [],
      "source": [
        "class RobertaLongSelfAttention(LongformerSelfAttention):\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask=None,\n",
        "        head_mask=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        return super().forward(hidden_states, attention_mask=attention_mask, output_attentions=output_attentions)\n",
        "\n",
        "\n",
        "class RobertaLongForMaskedLM(RobertaForMaskedLM):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        for i, layer in enumerate(self.roberta.encoder.layer):\n",
        "            # replace the `modeling_bert.BertSelfAttention` object with `LongformerSelfAttention`\n",
        "            layer.attention.self = RobertaLongSelfAttention(config, layer_id=i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LRZa5s1bD6E"
      },
      "source": [
        "Starting from the `roberta-base` checkpoint, the following function converts it into an instance of `RobertaLong`. It makes the following changes:\n",
        "\n",
        "- extend the position embeddings from `512` positions to `max_pos`. In Longformer, we set `max_pos=4096`\n",
        "\n",
        "- initialize the additional position embeddings by copying the embeddings of the first `512` positions. This initialization is crucial for the model performance (check table 6 in [the paper](https://arxiv.org/pdf/2004.05150.pdf) for performance without this initialization)\n",
        "\n",
        "- replaces `modeling_bert.BertSelfAttention` objects with `modeling_longformer.LongformerSelfAttention` with a attention window size `attention_window`\n",
        "\n",
        "The output of this function works for long documents even without pretraining. Check tables 6 and 11 in [the paper](https://arxiv.org/pdf/2004.05150.pdf) to get a sense of the expected performance of this model before pretraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m4A_ttixPuf"
      },
      "outputs": [],
      "source": [
        "def create_long_model(save_model_to, attention_window, max_pos):\n",
        "    model = RobertaForMaskedLM.from_pretrained('klue/roberta-large')\n",
        "    tokenizer = RobertaTokenizerFast.from_pretrained('klue/roberta-large', model_max_length=max_pos)\n",
        "    config = model.config\n",
        "\n",
        "    # extend position embeddings\n",
        "    tokenizer.model_max_length = max_pos\n",
        "    tokenizer.init_kwargs['model_max_length'] = max_pos\n",
        "    current_max_pos, embed_size = model.roberta.embeddings.position_embeddings.weight.shape\n",
        "    max_pos += 2  # NOTE: RoBERTa has positions 0,1 reserved, so embedding size is max position + 2\n",
        "    config.max_position_embeddings = max_pos\n",
        "    assert max_pos > current_max_pos\n",
        "    # allocate a larger position embedding matrix\n",
        "    new_pos_embed = model.roberta.embeddings.position_embeddings.weight.new_empty(max_pos, embed_size)\n",
        "    # copy position embeddings over and over to initialize the new position embeddings\n",
        "    k = 2\n",
        "    step = current_max_pos - 2\n",
        "    while k < max_pos - 1:\n",
        "        new_pos_embed[k:(k + step)] = model.roberta.embeddings.position_embeddings.weight[2:]\n",
        "        k += step\n",
        "    model.roberta.embeddings.position_embeddings.weight.data = new_pos_embed\n",
        "    model.roberta.embeddings.position_ids.data = torch.tensor([i for i in range(max_pos)]).reshape(1, max_pos)\n",
        "\n",
        "    # replace the `modeling_bert.BertSelfAttention` object with `LongformerSelfAttention`\n",
        "    config.attention_window = [attention_window] * config.num_hidden_layers\n",
        "    for i, layer in enumerate(model.roberta.encoder.layer):\n",
        "        longformer_self_attn = LongformerSelfAttention(config, layer_id=i)\n",
        "        longformer_self_attn.query = layer.attention.self.query\n",
        "        longformer_self_attn.key = layer.attention.self.key\n",
        "        longformer_self_attn.value = layer.attention.self.value\n",
        "\n",
        "        longformer_self_attn.query_global = copy.deepcopy(layer.attention.self.query)\n",
        "        longformer_self_attn.key_global = copy.deepcopy(layer.attention.self.key)\n",
        "        longformer_self_attn.value_global = copy.deepcopy(layer.attention.self.value)\n",
        "\n",
        "        layer.attention.self = longformer_self_attn\n",
        "\n",
        "    logger.info(f'saving model to {save_model_to}')\n",
        "    model.save_pretrained(save_model_to)\n",
        "    tokenizer.save_pretrained(save_model_to)\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkbQvhOMbD6L"
      },
      "source": [
        "Pretraining on Masked Language Modeling (MLM) doesn't update the global projection layers. After pretraining, the following function copies `query`, `key`, `value` to their global counterpart projection matrices.\n",
        "For more explanation on \"local\" vs. \"global\" attention, please refer to the documentation [here](https://huggingface.co/transformers/model_doc/longformer.html#longformer-self-attention)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO3MoEgCxP9W"
      },
      "outputs": [],
      "source": [
        "def copy_proj_layers(model):\n",
        "    for i, layer in enumerate(model.roberta.encoder.layer):\n",
        "        layer.attention.self.query_global = copy.deepcopy(layer.attention.self.query)\n",
        "        layer.attention.self.key_global = copy.deepcopy(layer.attention.self.key)\n",
        "        layer.attention.self.value_global = copy.deepcopy(layer.attention.self.value)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KjI9f8BbD6S"
      },
      "source": [
        "### Pretrain and Evaluate on masked language modeling (MLM)\n",
        "\n",
        "The following function pretrains and evaluates a model on MLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqY_Hg5HbD6a"
      },
      "source": [
        "**Training hyperparameters**\n",
        "\n",
        "- Following RoBERTa pretraining setting, we set number of tokens per batch to be `2^18` tokens. Changing this number might require changes in the lr, lr-scheudler, #steps and #warmup steps. Therefor, it is a good idea to keep this number constant.\n",
        "\n",
        "- Note that: `#tokens/batch = batch_size x #gpus x gradient_accumulation x seqlen`\n",
        "   \n",
        "- In [the paper](https://arxiv.org/pdf/2004.05150.pdf), we train for 65k steps, but 3k is probably enough (check table 6)\n",
        "\n",
        "- **Important note**: The lr-scheduler in [the paper](https://arxiv.org/pdf/2004.05150.pdf) is polynomial_decay with power 3 over 65k steps. To train for 3k steps, use a constant lr-scheduler (after warmup). Both lr-scheduler are not supported in HF trainer, and at least **constant lr-scheduler** will need to be added.\n",
        "\n",
        "- Pretraining will take 2 days on 1 x 32GB GPU with fp32. Consider using fp16 and using more gpus to train faster (if you increase `#gpus`, reduce `gradient_accumulation` to maintain `#tokens/batch` as mentioned earlier).\n",
        "\n",
        "- As a demonstration, this notebook is training on wikitext103 but wikitext103 is rather small that it takes 7 epochs to train for 3k steps Consider doing a single epoch on a larger dataset (800M tokens) instead.\n",
        "\n",
        "- Set #gpus using `CUDA_VISIBLE_DEVICES`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl_hDDlryVo2"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelArgs:\n",
        "    attention_window: int = field(default=512, metadata={\"help\": \"Size of attention window\"})\n",
        "    max_pos: int = field(default=4096, metadata={\"help\": \"Maximum position\"})\n",
        "\n",
        "parser = HfArgumentParser((TrainingArguments, ModelArgs,))\n",
        "\n",
        "training_args, model_args = parser.parse_args_into_dataclasses(look_for_args_file=False, args=[\n",
        "    '--output_dir', '/content/drive/MyDrive/projects/ExpertLLM/model/',\n",
        "    '--warmup_steps', '150',\n",
        "    '--learning_rate', '0.0003',\n",
        "    '--weight_decay', '0.01',\n",
        "    '--adam_epsilon', '1e-6',\n",
        "    '--max_steps', '700',\n",
        "    '--logging_steps', '3',\n",
        "    #'--save_steps', '500',\n",
        "    '--max_grad_norm', '5.0',\n",
        "    '--per_device_eval_batch_size', '8',\n",
        "    '--per_device_train_batch_size', '1',  # 32GB gpu with fp32\n",
        "    '--gradient_accumulation_steps', '32',\n",
        "    #'--evaluate_during_training',\n",
        "    '--do_train',\n",
        "    '--do_eval',\n",
        "])\n",
        "training_args.val_datapath = main_path / 'sample_train_4000.csv'\n",
        "training_args.train_datapath = main_path / 'sample_val_4000.csv'\n",
        "\n",
        "# Choose GPU\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi5ZIKcsbD6e"
      },
      "source": [
        "### Put it all together\n",
        "\n",
        "1) Evaluating `roberta-base` on MLM to establish a baseline. Validation `bpc` = `2.536` which is higher than the `bpc` values in table 6 [here](https://arxiv.org/pdf/2004.05150.pdf) because wikitext103 is harder than our pretraining corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiKj7D1c1ovy",
        "outputId": "9bb49390-3bce-40b0-beef-3f20f5ac06a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizerFast'.\n"
          ]
        }
      ],
      "source": [
        "roberta_base = RobertaForMaskedLM.from_pretrained('klue/roberta-large')\n",
        "roberta_base_tokenizer = RobertaTokenizerFast.from_pretrained('klue/roberta-large')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBXU3r69bD6l"
      },
      "source": [
        "2) As descriped in `create_long_model`, convert a `roberta-base` model into `roberta-base-4096` which is an instance of `RobertaLong`, then save it to the disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7tcsSfZ1-b9",
        "outputId": "c526e1c9-ac9f-44f8-c2f7-9dcf43f6f599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'RobertaTokenizerFast'.\n"
          ]
        }
      ],
      "source": [
        "model_path = f'{training_args.output_dir}/roberta-large-{model_args.max_pos}'\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "logger.info(f'Converting roberta-large into roberta-large-{model_args.max_pos}')\n",
        "model, tokenizer = create_long_model(\n",
        "    save_model_to=model_path, attention_window=model_args.attention_window, max_pos=model_args.max_pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiftMH3-zPUS"
      },
      "source": [
        "3) Load `roberta-base-4096` from the disk. This model works for long sequences even without pretraining. If you don't want to pretrain, you can stop here and start finetuning your `roberta-base-4096` on downstream tasks 🎉🎉🎉"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8vNeYdrzMd2"
      },
      "outputs": [],
      "source": [
        "logger.info(f'Loading the model from {model_path}')\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_path)\n",
        "model = RobertaLongForMaskedLM.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS0Np2F4bD6p"
      },
      "source": [
        "4) Pretrain `roberta-base-4096` for `3k` steps, each steps has `2^18` tokens. Notes:\n",
        "\n",
        "- The `training_args.max_steps = 3 ` is just for the demo. **Remove this line for the actual training**\n",
        "\n",
        "- Training for `3k` steps will take 2 days on a single 32GB gpu with `fp32`. Consider using `fp16` and more gpus to train faster.\n",
        "\n",
        "- Tokenizing the training data the first time is going to take 5-10 minutes.\n",
        "\n",
        "- MLM validation `bpc` **before** pretraining: **2.652**, a bit worse than the **2.536** of `roberta-base`. As discussed in [the paper](https://arxiv.org/pdf/2004.05150.pdf) this is expected because the model didn't learn yet to work with the sliding window attention.\n",
        "\n",
        "- MLM validation `bpc` after pretraining for a few number of steps: **2.628**. It is quickly getting better. By 3k steps, it should be better than the **2.536** of `roberta-base`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GOc0_6SbD6u"
      },
      "source": [
        "5) Copy global projection layers. MLM pretraining doesn't train global projections, so we need to call `copy_proj_layers` to copy the local projection layers to the global ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obupoA0FbD6v"
      },
      "outputs": [],
      "source": [
        "logger.info(f'Copying local projection layers into global projection layers ... ')\n",
        "model = copy_proj_layers(model)\n",
        "logger.info(f'Saving model to {model_path}')\n",
        "model.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOBmcHTj3NPz"
      },
      "outputs": [],
      "source": [
        "logger.info(f'Loading the model from {model_path}')\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_path)\n",
        "model = RobertaLongForMaskedLM.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I50JkSLXDRNS",
        "outputId": "7b675e88-8d76-40cd-a0c5-cc386614c82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaLongForMaskedLM(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(4098, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaLongSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (query_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (decoder): Linear(in_features=1024, out_features=32000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "longformer = LongformerForMaskedLM.from_pretrained('allenai/longformer-large-4096')\n",
        "longformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dECyeERME63u",
        "outputId": "e192b5ce-f5ab-4b17-bbbf-294a038133fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LongformerForMaskedLM(\n",
              "  (longformer): LongformerModel(\n",
              "    (embeddings): LongformerEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (position_embeddings): Embedding(4098, 1024, padding_idx=1)\n",
              "    )\n",
              "    (encoder): LongformerEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (query_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): LongformerSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LongformerIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LongformerOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): LongformerLMHead(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (decoder): Linear(in_features=1024, out_features=50265, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_longformer(model):\n",
        "    new_model = LongformerForMaskedLM.from_pretrained('allenai/longformer-large-4096')\n",
        "    new_model.longformer.embeddings.word_embeddings = model.roberta.embeddings.word_embeddings\n",
        "    new_model.longformer.embeddings.token_type_embeddings = model.roberta.embeddings.token_type_embeddings\n",
        "    new_model.longformer.embeddings.LayerNorm = model.roberta.embeddings.LayerNorm\n",
        "    new_model.longformer.embeddings.position_embeddings = model.roberta.embeddings.position_embeddings\n",
        "    for i, layer in enumerate(new_model.longformer.encoder.layer):\n",
        "        layer.attention.self.query = model.roberta.encoder.layer[i].attention.self.query\n",
        "        layer.attention.self.query_global = model.roberta.encoder.layer[i].attention.self.query_global\n",
        "        layer.attention.self.key = model.roberta.encoder.layer[i].attention.self.key\n",
        "        layer.attention.self.key_global = model.roberta.encoder.layer[i].attention.self.key_global\n",
        "        layer.attention.self.value = model.roberta.encoder.layer[i].attention.self.value\n",
        "        layer.attention.self.value_global = model.roberta.encoder.layer[i].attention.self.value_global\n",
        "        layer.attention.output.dense = model.roberta.encoder.layer[i].attention.output.dense\n",
        "        layer.attention.output.LayerNorm = model.roberta.encoder.layer[i].attention.output.LayerNorm\n",
        "        layer.intermediate.dense = model.roberta.encoder.layer[i].intermediate.dense\n",
        "        layer.output.dense = model.roberta.encoder.layer[i].output.dense\n",
        "        layer.output.LayerNorm = model.roberta.encoder.layer[i].output.LayerNorm\n",
        "    new_model.config.vocab_size = model.config.vocab_size\n",
        "    new_model.config.hidden_size = model.config.hidden_size\n",
        "    new_model.config.num_hidden_layers = model.config.num_hidden_layers\n",
        "    new_model.config.num_attention_heads = model.config.num_attention_heads\n",
        "    new_model.config.type_vocab_size = model.config.type_vocab_size\n",
        "    new_model.config.max_position_embeddings = model.config.max_position_embeddings\n",
        "    new_model.config.attention_window = model.config.attention_window\n",
        "\n",
        "    new_model.lm_head.dense = model.lm_head.dense\n",
        "    new_model.lm_head.layer_norm = model.lm_head.layer_norm\n",
        "    new_model.lm_head.decoder = model.lm_head.decoder\n",
        "    return new_model"
      ],
      "metadata": {
        "id": "8s8D67C3DF5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longfomer_model = to_longformer(model)\n",
        "longfomer_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD_rsDGBEcxt",
        "outputId": "dbeb0e24-6691-4ebb-8b93-05b402a34a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LongformerForMaskedLM(\n",
              "  (longformer): LongformerModel(\n",
              "    (embeddings): LongformerEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (position_embeddings): Embedding(4098, 1024, padding_idx=1)\n",
              "    )\n",
              "    (encoder): LongformerEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x LongformerLayer(\n",
              "          (attention): LongformerAttention(\n",
              "            (self): LongformerSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (query_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value_global): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            )\n",
              "            (output): LongformerSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): LongformerIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): LongformerOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): LongformerLMHead(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (decoder): Linear(in_features=1024, out_features=32000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(pd.read_csv(training_args.train_datapath))\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxVPNEJ2GhjO",
        "outputId": "3d20012d-027b-45bb-9b68-ca4d8faf47f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 75042\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
      ],
      "metadata": {
        "id": "v-BNZltgKZVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(lambda examples: tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True), batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6624c48592ab43529d1e27f637e0daab",
            "e535c740b1e94e40a5528a94b66ecd02",
            "0b160a7aee7546e3b174f7e043fc9596",
            "dd6f057111074c5a99683b7032235a90",
            "85ff2f7746c34e0a81ab2b9429d4ecb4",
            "f635f67896ae4d6192afee11469640c1",
            "0d2d962999564669b57443efc3d85859",
            "73b6e921f7fe44bc829d97ea1db81b51",
            "8e2dda13b8e840a995102b564419f48c",
            "b9a637319d6b44ad995c36331886da67",
            "0429569c8aff4efaa7181518ce00c892"
          ]
        },
        "id": "Ix4cR1BjKn26",
        "outputId": "e270ca92-4d93-4ecd-ae5a-bf977b4f6ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/75042 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6624c48592ab43529d1e27f637e0daab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=longfomer_model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynlb_5jYKw3O",
        "outputId": "b42a1964-0555-48a2-fc41-89d7f1b19a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset[0]['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHkWyUVteCnD",
        "outputId": "ffccc3ef-a656-4aff-a0d1-4561b7f473d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4096"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZwvIIIO6Isyn",
        "outputId": "b241d5f2-7189-4981-946e-a6ab853bd2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [700/700 8:15:30, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.539300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4.148200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.560900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.675000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.523800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.426100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.340200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.150800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.228500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.172600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.153200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.171900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.071000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.156200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.153000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.094000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.987800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.063400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.247200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.099300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.177800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.086800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.164000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.242500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.129700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.217300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.219600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.215200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.203500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.311200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.270100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>1.296800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.263800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>1.334800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.356500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>1.376200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>1.440400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.453400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>1.533600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>1.545200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>1.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>1.598200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.494100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>1.473600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>1.657200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>1.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>1.500800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.620800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>1.637600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>1.536700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>1.654300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>1.696300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>1.755500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>1.599600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>1.631000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>1.677600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>1.666000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.738200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>1.670700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>1.779200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>1.897300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>1.794800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>1.670900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>1.748700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>1.762100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>1.655300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>1.797300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.711000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>1.798100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>1.801400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>1.755200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>1.853200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.741000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>1.699000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>1.735600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.651300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>1.670000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.614400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>1.681600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>1.817900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>1.729200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>1.526300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>1.658300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>1.758800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>1.799400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>1.669800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>1.682800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.613400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>1.580600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>1.743300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>1.683300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>1.691500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>1.583300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>1.648800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>1.625500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>1.548300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>1.630000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.519500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>1.711600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>1.619900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>309</td>\n",
              "      <td>1.548300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>1.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>1.581700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>318</td>\n",
              "      <td>1.651400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>321</td>\n",
              "      <td>1.576900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>1.558400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>327</td>\n",
              "      <td>1.568100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.632600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>333</td>\n",
              "      <td>1.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>1.550700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>339</td>\n",
              "      <td>1.633600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>342</td>\n",
              "      <td>1.490800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>1.663600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>348</td>\n",
              "      <td>1.543300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>1.480300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>354</td>\n",
              "      <td>1.579800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>357</td>\n",
              "      <td>1.532900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.653800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>363</td>\n",
              "      <td>1.541700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>366</td>\n",
              "      <td>1.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>369</td>\n",
              "      <td>1.726500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>1.532600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.538100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>378</td>\n",
              "      <td>1.510400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>381</td>\n",
              "      <td>1.567300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>384</td>\n",
              "      <td>1.395600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>387</td>\n",
              "      <td>1.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.452500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>393</td>\n",
              "      <td>1.516900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>396</td>\n",
              "      <td>1.512800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>399</td>\n",
              "      <td>1.413200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>402</td>\n",
              "      <td>1.551900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>1.499700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>408</td>\n",
              "      <td>1.464400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>411</td>\n",
              "      <td>1.540100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>414</td>\n",
              "      <td>1.468700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>417</td>\n",
              "      <td>1.474900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.396900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>423</td>\n",
              "      <td>1.492900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>426</td>\n",
              "      <td>1.463500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>429</td>\n",
              "      <td>1.376600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>432</td>\n",
              "      <td>1.469900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>1.502200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>438</td>\n",
              "      <td>1.419400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>441</td>\n",
              "      <td>1.446800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>444</td>\n",
              "      <td>1.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>447</td>\n",
              "      <td>1.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.509600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>453</td>\n",
              "      <td>1.448300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>456</td>\n",
              "      <td>1.543100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>459</td>\n",
              "      <td>1.460500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>462</td>\n",
              "      <td>1.460500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>1.416000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>1.485500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>471</td>\n",
              "      <td>1.427200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>474</td>\n",
              "      <td>1.351800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>477</td>\n",
              "      <td>1.426500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.419600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>483</td>\n",
              "      <td>1.394900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>486</td>\n",
              "      <td>1.469800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>489</td>\n",
              "      <td>1.452600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>492</td>\n",
              "      <td>1.356200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>1.434100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>498</td>\n",
              "      <td>1.376000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>501</td>\n",
              "      <td>1.457800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>504</td>\n",
              "      <td>1.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>507</td>\n",
              "      <td>1.381800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>1.336500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>513</td>\n",
              "      <td>1.227900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>516</td>\n",
              "      <td>1.449500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>519</td>\n",
              "      <td>1.388500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>522</td>\n",
              "      <td>1.352200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>1.346100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>528</td>\n",
              "      <td>1.311600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>531</td>\n",
              "      <td>1.294900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>534</td>\n",
              "      <td>1.263700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>537</td>\n",
              "      <td>1.382600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.384900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>543</td>\n",
              "      <td>1.333900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>546</td>\n",
              "      <td>1.338800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>549</td>\n",
              "      <td>1.405500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>552</td>\n",
              "      <td>1.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>555</td>\n",
              "      <td>1.275200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>1.265200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>561</td>\n",
              "      <td>1.346500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>564</td>\n",
              "      <td>1.273500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>567</td>\n",
              "      <td>1.299100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>1.287700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>573</td>\n",
              "      <td>1.273600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>576</td>\n",
              "      <td>1.282400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>579</td>\n",
              "      <td>1.316800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>582</td>\n",
              "      <td>1.337600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>585</td>\n",
              "      <td>1.262800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>588</td>\n",
              "      <td>1.193900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>591</td>\n",
              "      <td>1.285100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>594</td>\n",
              "      <td>1.195000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>597</td>\n",
              "      <td>1.232400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.257700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>603</td>\n",
              "      <td>1.193500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>606</td>\n",
              "      <td>1.204000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>609</td>\n",
              "      <td>1.161900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>612</td>\n",
              "      <td>1.250800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>615</td>\n",
              "      <td>1.223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>618</td>\n",
              "      <td>1.073000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>621</td>\n",
              "      <td>1.183200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>624</td>\n",
              "      <td>1.131500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>627</td>\n",
              "      <td>1.164800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>1.171300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>633</td>\n",
              "      <td>1.286300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>636</td>\n",
              "      <td>1.237100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>639</td>\n",
              "      <td>1.100100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>642</td>\n",
              "      <td>1.225400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>645</td>\n",
              "      <td>1.278800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>648</td>\n",
              "      <td>1.155100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>1.196700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>654</td>\n",
              "      <td>1.128800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>657</td>\n",
              "      <td>1.206600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>1.218100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>663</td>\n",
              "      <td>1.162900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>666</td>\n",
              "      <td>1.139800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>669</td>\n",
              "      <td>1.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>672</td>\n",
              "      <td>1.181400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>1.215400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>678</td>\n",
              "      <td>1.218500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>681</td>\n",
              "      <td>1.163700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>684</td>\n",
              "      <td>1.111600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>687</td>\n",
              "      <td>1.140400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>1.225800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>693</td>\n",
              "      <td>1.152200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>696</td>\n",
              "      <td>1.190200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>699</td>\n",
              "      <td>1.224000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=700, training_loss=1.4610219935008457, metrics={'train_runtime': 29773.7298, 'train_samples_per_second': 0.752, 'train_steps_per_second': 0.024, 'total_flos': 2.086495132581888e+17, 'train_loss': 1.4610219935008457, 'epoch': 0.2984995069427787})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(f'{training_args.output_dir}/longformer-large-4096-800')"
      ],
      "metadata": {
        "id": "8uR7YQwgNoBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6624c48592ab43529d1e27f637e0daab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e535c740b1e94e40a5528a94b66ecd02",
              "IPY_MODEL_0b160a7aee7546e3b174f7e043fc9596",
              "IPY_MODEL_dd6f057111074c5a99683b7032235a90"
            ],
            "layout": "IPY_MODEL_85ff2f7746c34e0a81ab2b9429d4ecb4"
          }
        },
        "e535c740b1e94e40a5528a94b66ecd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f635f67896ae4d6192afee11469640c1",
            "placeholder": "​",
            "style": "IPY_MODEL_0d2d962999564669b57443efc3d85859",
            "value": "Map: 100%"
          }
        },
        "0b160a7aee7546e3b174f7e043fc9596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b6e921f7fe44bc829d97ea1db81b51",
            "max": 75042,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e2dda13b8e840a995102b564419f48c",
            "value": 75042
          }
        },
        "dd6f057111074c5a99683b7032235a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9a637319d6b44ad995c36331886da67",
            "placeholder": "​",
            "style": "IPY_MODEL_0429569c8aff4efaa7181518ce00c892",
            "value": " 75042/75042 [01:54&lt;00:00, 668.69 examples/s]"
          }
        },
        "85ff2f7746c34e0a81ab2b9429d4ecb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f635f67896ae4d6192afee11469640c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2d962999564669b57443efc3d85859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73b6e921f7fe44bc829d97ea1db81b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2dda13b8e840a995102b564419f48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9a637319d6b44ad995c36331886da67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0429569c8aff4efaa7181518ce00c892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}